# Java 
## Аннотации
* @Cacheable - сохранение данных в КЭШ (Redis). Альтернатива template.
* @Async - вызов асинхронной работы метода (когда не требуется ожидание результата). Не сработает, если вызывается метод внутри класса.
* @GeneratedValue(strategy = GenerationType.IDENTITY)
* @Transactional - реализует паттерн прокси
* @Transient - ORM игнорирует поле для добавление в БД;
* @JsonIgnor - исключение из DTO поле;

Аннотации - интерфейсы, маркеры.
* Игнорируются при компиляции. @Override, @Depricated;
* Компилируются и удаляются @FunctionalInterface, @Retention;
* Используются все время @Entity, @Autowired.
``` java
@ManyToMany(fetch = FetchType.LAZY)
  @JoinTable(
      name = "game_player",
      joinColumns = @JoinColumn(name = "game_id"),
      inverseJoinColumns = @JoinColumn(name = "player_id")
  )
// С другой стороны используется лишь
@ManyToMany(mappedBy = "players")
```

## Типы данных
Generic - при компиляции сводятся к Object;
### String
* toCharArray() - массив символов;
* indexOf() - первый индекс входящий в подстроку;
* replace() - замена в строке подстроку на другую;
* substring() - возвращение с индекса по индекс;
* length() - длинна;
* charAt() - возвращение символа по индексу;
* intern() - возвращение строки в String pool.

String.valueOf() - преобразование в строку;
Integer.parseInt("") - преобразование строки в int;
StringBuilder:
* append() - добавить элемент;
* deleteCharAt() - удаление символа;
* reverse() - изменение порядка

String.format("... %d", num); Подстановка элементов в строку
%d - целое число;
%f - вещественное число;
%b - boolean;
%t - data;
%s - строка.
### List
```java 
List<String> list = new ArrayList<>();
String[] str = list.toArray();
``` 
### Map
* keySet() - сет ключей;
* entrySet - для Map.Entry<,> entry значения в HashMap;
* values - список значений;
* size() - размер, не length;
* put(key, value) - положить значение;
* containsKey() - есть ли ключ;
* equals() - сравнение коллекций.

Создание Map, где key - символ, value - частота появления в последовательнсти.
Создание Map, где key - значение числа, value - индекс.

Если в Map как ключ кладем изменяемое значение, то при изменении поменяется и ХЭШ, а объект мы найти не сможем.

### Stream
Stream.of(" ", " ", ...)

* .stream( ) - преобразование в стрим
* .filter(x -> x.length == 3) - фильтрация
* .forEach() - вывод
* map(x -> x+3) преобразование каждого элемента
* limit(3)/skip() - ограничение проходов элементов
* collect(Collectors.toList()/toSet()) - преобразование
* avarage() - среднее


## JMM
Связано с [[#Многопоточка]]. 

Память состоит из Кучи (heap) и Стека (Stack). В первом хранятся все ссылочные типы, во втором примитивы и сами ссылки.

1. Видимость. Изменение переменных в потоке видно всем;
2. Перестановки инструкции для оптимизации. Главное не нарушает логику.
3. Атомарность операций. Должна выполняться целостно.
4. happends-before - основной концепт. Операция в этом отношении гарантирует видимость изменения для следующих действий. (syncronized, volatile...)

Garbage Collector - сборщик мусора. Имеются разные реализации. Чаще всего GC - останавливает работу потоков для пометки не задействованных полей, а очистка происзодит параллельно. Есть 4 зоны: Легкая, S0, S1, Тяжелая. Туда помещаются объекты в зависимости от их актуальности. 

Задержка - время приостановки программы для одной сборки;
Пропускная способность - трата ресурсов на сборку и общее время / время простоя;
Потребление ресурсов - память, процессор. 

## Exception
Checked - проверяемые:
1. IOException;
2. SQLException;
3. FileNotFoundException.

Unchecked - не проверяемые:
1. RuntimeException;
2. NullPointerException;

Error - ошибки:
1. StackOverflowException

Можно использовать @ControllerAdvice - место, где лежат обработчики исключений, над методом @ExceptionHanndler - задается обработка исключения
``` java 
@ExceptionHandler(Exception.class)
    public ResponseEntity<String> handleGeneric(Exception ex) {
        return ResponseEntity
                .status(HttpStatus.INTERNAL_SERVER_ERROR)
                .body("Что-то пошло не так");
    }
```

## Hibernate
2 уровня КЭШа: сессионный и общий. Сессионный подключается автоматически. Кроме аннотации нужно "прикрутить" Hazlcast, Coffein, Redis. Spring DATA Cashe.

## Generic
``` java
public static < T > void printArray(T[] array){
for (T obj : array){
System.out.printLn(obj);
}
} 
//

public class Box<T>{
private T value;

public get(){ }

public set(T value){ this.value = value}

}

```

< T extends Number> - все элементы должны наследоваться от Number
< ? super Integer> - все классы выше Integer
# БД
## Транзакции
Всегда АТОМАРНЫ - либо сработала, либо нет.

* READ_UNCOMMITED - ничего не блокирует
* READ_COMMITED - по умолчанию в PostgreSQL нет грязного чтения (неповторяемое)
* REPETEABLE_READ - по умолчанию в MySQL нет грязного/неповторяемого чтения (фантомные чтения)
* SERIALIZABLE - блокирует все (медленно работает)

**Грязное чтение**: Одна транзакция читает незафиксированные данные другой.
**Неповторяемое чтение**: Одна транзакция читает дважды одни и те же строки, потому что вторая транзакция их изменила.
**Фантомное чтение**: Одна отправляет запрос, вторая удаляет или изменяет строки, которые влияют на результат.

@Transactional(propagation = Propagation.REQUEST_NEW) - для принудительного открытия новой транзакции. Не работает, если методы вызываются внутри ОДНОГО класса.

## Запросы
1. **SELECT** * FROM table_name WHERE num **BETWEEN** a **AND** b;
2. UPDATE table_name SET name = "name" WHERE id **IN** (SELECT user_id FROM orders WHERE total > 1000);
3. DELETE FROM table_name where id = 12;
4. SELECT city, **COUNT**( * ) as user_count FROM users **GROUP BY** city **HAVING** COUNT( * ) > 18
5. SELECT u.name, o.total FROM users u **INNER JOIN** orders o ON u.id = o.user_id;

## Концепт в JAVA
Модель ORM (Object Relationship Model) -> стандарт JPA из API -> реализация Hibernate 
Hibernate позволяет хранить данные в памяти для уменьшения запросов к БД.
Spring Date -> JPA -> JDBC

## SQL инъекции
Когда в код передается SQL вместе с полями, которые не контролируются. Так могут встроить удобный запрос для изменение БД. Нужно использовать PreparedStatement. Либо ORM/Spring Data

## Проблемы
N+1, когда идет связь одной библиотеки, потом другой и так до бесконечности. Можно использовать Lazy, Egger, MaxFetch для создания ограничений.

Использовать **протеционирование** - разбиение таблиц на более мелкие
# Kafka
## Общая 
	Kafka - брокер сообщений, который является "шиной" между пользователями и сервисом, между сервисами. Используется несколько брокеров для отказоустойчивости. Так, при выходе из строя одного, уведомление подхватит другой.
1. Существует множество брокеров, некоторые друг с другом связаны;
2. Каждый брокер имеет топики "темы", куда отправляются сообщения;
3. Топики делятся на партиции, где хранятся сообщении и затем отправляются consumer.

Топики обрабатываются параллельно, партиции последовательно. Можно настроить, что разные партиции одного топика будут находиться в разных брокерах. 

Это уменьшает загруженность и трафик.

Работа происходит также как и в [[#Redis]]. 
Создание Config либо описание в yaml файле application:
``` java
@Configuration
public class KafkaConfig{
@Bean
public ProducerFactory<String, class> producerFactory{
Map<String, Object> conf = new HashMap<>();
conf.put... // Настройка сериализации и десериализации для consumer и producer
}
}
```

Отправка данных kafkaTemplate.send("topic", класс), получение @KafkaListener(topics = "topic")

| Kafka                                                       | RabbitMQ                                                                          |
| ----------------------------------------------------------- | --------------------------------------------------------------------------------- |
| Долгосрочное хранение                                       | Краткосрочное хранение                                                            |
| Очень высокая производительность для большого объема данных | Высокая производительность для массовых передач                                   |
| Сообщения хранятся                                          | Удаляются после отправки                                                          |
| Большой поток данных. Удобен для аналитики                  | Фоновые задачи и передачи отдельных сообщений с надеждой на доставку (асинхронно) |
## EDA
Kafka является частью EDA - Event Driver Achitecher - Событийно-ориентированная архитектура. 

Основной упор на события в системе:
* Уведомление -> триггер работы;
* Listener -> обработка уведомлений;
* Работает асинхронно;
* Низкая связанность.
Используется 2 паттерна проектирования:
1. Event Sourcing - шаблон, все события идут последовательно. Сохраняется время их отправки.
2. CQRS - ограничение на изменение и чтение данных.
# Docker
## Общая
1. Docker File - описание настроек для будущего Image. Откуда брать исходные архивы. Можно за основу уже брать созданные в Hub;
2. Docker Image - пакет/архив, содержащий в себе все необходимые данные: ОС, программу, библиотеки, настройки, конфигурации. Они нужны для запуска программы.
3. Docker Container - результат запуска изолированной программы из Image. Имеет свой порт, доступ к памяти и процессору. Можем отслеживать состояние, проблемы, потребления ресурсов;
4. Docker Hub - хранилище Image, в который мы можем сами загрузить данные, так и скачать уже готовые архивы для нашей программы для последующей настройки.
## Kubernetus
Отвечает за оркестрацию контейнеров, которые разворачиваются в определенных подах. Чаще всего 1 под = 1 контейнер. Существует главный узел Master и несколько его зеркал - Slave. Так, если один падает, то переключаемся на другой. Удобное отслеживание времени жизни.

Shedule отвечает за балансировку нагрузок, API Server настройка связ
# Spring
## Основная информация
Каскадные операции - @OneToMany, @ManyToMany (несколько видов каскадности - Detouch, Merge, Remove, Refresh, All). Идет определение связей после удаление объекта. Оставляем, связываем и тд. 

**@Component** - в объявляются **@Bean**
Вместо **@Autowired** можно использовать конструктор или сеттр. Если добавить final то можно использовать **@RequiredArgsConstructor**.

@Autowired - конструктор, поле, метод. required = true, тогда NoSuchBeanDefinitionException - не найден бин.

Вместо **@Controller** использовать **@RestController**, тогда при маппинге получаем сам объект. @RequestMapping(value = "/user") - на контроллер, @RequestBody - рядом с поступающим объектом. @GetMapping/@PostMapping - на метод

Либо в методе, либо в хэндлере **ResponseEntity**<Возвращаемый класс> return ResponseEntity<>(HttpStatus.NOT_FOUND.value()). Класс Spring обертки для возвращения данных Http-ответа. 

* Авторизация - получение доступа и выдача прав;
* Аутентификация - проверка подлинности пользователя через логин/пароль.

## Прокси
Прокси - это объекты-обертки, которые вызываются над стандартными бинами. К ним относятся Transactional, Async, Cacheable и т.д. Прокси не вызывается, если идет вызов метода в методе самого бина.

## Жизненный цикл
1. Создание объекта;
2. Установка зависимостей;
3. Вызов интерфейса Aware, если есть;
4. BeanPostProcessor (до инициализации);
5. BeanFactory;
6. BeanPostProcessor (после инициализации);
7. Использование;
8. Уничтожение.

## Работа Spring
Spring смотрит на Config, подтягивает зависимости 
1. Инициализирующий PostProcessor (пулл Bean);
2. ApplicationContext;
3. Создание BeanFactory;
4. Закрывающий PostProcessor

## BeanScope
Область видимости бина в программе:
* Singlton - один экземпляр на весь Spring;
* Prototype - при каждом новом вызове, создается новый бин;
* Request - для каждого нового Http запроса;
* Session - для каждой новой Http сессии;
* Application - один на СервлектКонтекст;
* Websocket - один на бин websocket.

Используется в программировании как @Scope(" ")

## Spring Security
Используется одностороннее ХЭШирование кода, последующее сравнение их для определение аутентификации. Как и в Map определяется bucket, в который будет помещаться ХЭШ. Bucket определяется делением на общее их количество, либо на заданную сложность. Иногда к ХЭШ добавляется "соль" - определенный код для защиты.

Реализация может быть через PasswordEncoder : BCryptPasswordEncoder.

## HttpServlet
Controller - своего рода HttpServlet, который работает с HttpServletRequest (запрос) и HttpServletResponse (ответ). @RequestBody - передает дополнительные параметры. @PathVariable - данные, которые передаются в URL.

Последовательность: **Web-Server/ServletContainer -> DispatcherServlet -> Controller**
Мы можем добавлять фильтры к запросу на уровне Servlet API
* @Conponent;
* Наследование от Filter;
* @Override init, destroy, doFilter
Использование Interceptor:
* @Coponent;
* implement HandlerInterceptor
* preHandler, postHandler.
Надо все прописывать в WebConfig

После DispatcherServlet сохраняются все данные:
1. HttpSession;
2. ApplicationContext;
3. ServletContext;
4. HttpServletRequest.

Сервлет - это класс обработчик http запросов. Основа работа веб-приложений. Контейнер сервлетов - сервер, отвечающий за жизненные циклы Сервлетов. Является частью TomCat

TomCat:
* Catalina - ядро контейнера (маршрутизация);
* Coyote - Http-контейнер (слушает порты);
* Jasper - слушает и компилирует JSP (JavaServer Pages - позволяет встраивать Java-код в HTML страницы);

Coyote -> Catalina -> DispatcherServlet -> Controller

## WebSocket
Постоянное двунаправленное соединение сервер-клиент. Экономия ресурсов, постоянное соединение, двунаправленная связь, уменьшение запросов. Проблема: сложное управление, доп ресурсы сервера, новое.

# Многопоточка
## Общая информация
Возможное создание потока: 
1. Наследование от класса Thread и переопределение run()
``` java 
public ThreadExample extends Thread
	@Override
	public void run(){
	
	}
```
2. Имплементация Runnable (иногда Callable)
``` java
public RunnableExample implements Runnable
	public void run(){
	
	}
//Создание объекта
Thread thread = new Thread(runnableExample)
```
Поля и методы потоков:
* id, name, daemon, priority; _daemon поток - это фоновые процессы, можно создать самостоятельно_
* getState () - проверка статуса;
* isAlive() - существует ли;
* join() - ожидание завершения потока
* start() - запускает поток; _без него ни один поток не отработает, даже если вызвать run_
* sleep() - засыпает на время в миллисекундах;
* yeld() - засыпает без времени

## Синхронизация
Каждый объект обладает mutex - отвечает за синхронизацию.

**volatile** - на переменную. Прямая запись в память, а не в КЭШ, но это не решение, лучше syncronized. Не обеспечивает атомарность, обеспечивает видимость
**syncronized** - ключевое слово, которое забирает монитор объекта, пока работа не окончена. Следовательно доступа к методу/блоку кода/переменной нет к других потоков. Обеспечивает и видимость, и атомарность.
**Semaphore** - управляет количеством разрешенных доступов к ресурсу. **acqure** - получает доступ .**release** - забирает
**CountDawnLatch** - альтернатива semaphore, однако ожидается N задач, после чего не работает.
**Atomic** - предоставляет атомарные операции (сравнение, установка, инкремент) без участия syncronized. Используется для высокопроизводительных операций.

**Race Condition** - состояние гонки (к ресурсу). Кто первый захватит ресурс, тот его и изменит.
**Forn/Join pool** - пул потоков для параллельной разработки. Используется в узком случае, к примеру, при очень больших коллекциях. Тогда они делятся на подзадачи и отдаются разным потокам. Как только один освобождается, он сразу перехватывает новый блок.
**Exchange** - позволяет соединиться потокам и обменяться данными. 
**ReentrantReadWriteLock** - ограничение доступа на изменение (1) и на чтение (n)


# Redis
## Функции
Пример использования внутри:
1. Присвоение значения - SET firstKey "Hello";
2. Просмотр значения - GET firstKey;
3. Удалить значение - DELETE firstKey;
4. Все значения - KEYS * ;
5. Добавить что-то к числу - INCRBY num 3;
6. Работа со списками, добавление элемента - LPUSH/RPUSH cars "Toyota";
7. Все значения в списке по индексу - LRANGE cars 0 - 1;
8. Достает первый элемент из списка - LPOP cars;
9. Длина списка -  LLEN cars;
10. Добавление элемента из списка в список - LMOVE cars sold LEFT LEFT;
11. Сколько времени жизни - TTL;
12. Задается время жизни - EXPIRE sec;

## Основная информация
Редис - это надстройка над БД, NoSql, которая представляет из себя ХЭШ в RAM (оперативной памяти). Она во много раз ускоряет процесс работы с записями. Работает как пара KEY - VALUE.

Redis - скорость, Cassandra - много записей, mongoDB - данные без структуры.
BASE:
* BA - Base Availability. Базовая доступность, всегда есть доступ к данным;
* S - Soft State. Мягкое состояние, могут быть неактуальные данные при перенаправлении на Slave кластер;
* E - Eventual Consistance. Непротеворечивость в конечном итоге, гарантия доставки данных.
## Внутри Java
1. Установка и развертывание Redis (Docker/Сервер);
2. Добавление зависимостей и подгрузка библиотек;
3. Настройка application.yaml;
4. Создание RedisConfig и Bean для настройки RedisTemplate;
5. Работа reditTemplate.set( , ) - положить значение по ключу, reditTemplate.get() - получить значение по ключу.

Можно работать как с RedisTemplate, так и с аннотациями @Cacheable(value = "users", keys = "#id"). Существует Pub/Sub - аналог Kafka.

Создается топик, на который подписывается сервис. При его обновлении отсылается уведомление.
1. Создание RedisPubSubConfig;
2. Используется RedisMessageListenerContainer.
``` java 
listenerContainer.addMessageListener(
(message, pattern) -> {
try{
body = new String(message.body(), StandartCharsets.UTF_8)
}
}
)
```
Это подписка и логика при обработке
Не забывать о @EventListener(ContentRefreshedEvent.class)

## Разгрузка БД
Для уменьшение запросов к БД мы можем использовать Redis. Но если и он страдает из-за частых запросов, то мы можем сохранять данные внутри сервисов с помощью Gueue и Caggine, сложность работы O(1).
# Архитектура
## SOLID
1. S -> Single Responsibility Principal (Единственная ответственность). Не должно быть больше одной причины изменить класс. 1 функционал = 1 класс
2. O -> Open-closed Pricipal (Открытость - закрытость). Сущность открыта для расширения, но закрыта для изменения.
3. L -> Liskpv's Substit Principal (Подстановка Лискова). При расширении класса не должна нарушаться логика ожидания переопределения методов. Вместо класса родителя можно было бы использовать класс наследника.
4. I -> Interface Segrafation Principal (Разделение интерфейсов). РАзделение больших интерфейсов на несколько мелких. Не стоит реализовывать ненужные методы.
5. D -> Dependency Injection (Инверсия зависимостей) Абстракции не зависят от деталей. К примеру, Spring. Нет явного указания на детали.

## Микросервисная архитектура
1. API-шлюз - точки вхоода клиента для общения с сервисами. Отвечают за безопасность и маршрутизацию.
   * Пользователь обращается в API-шлюз, а не к сервису напрямую;
   * API знает маршрут, это снимает нагрузку с пользователя;
   * Безопасность - проверка токенов для доступа;
   * Агрегация - один запрос: данные из разных сервисов.
   * КЭШ.
2. Server Discovery - обнаружение сервисов. При использовании облачного хранилища или больших серверов сервисы могут иметь динамический адрес. SD отслеживает и направляет их.
3. Circuit Breaker - автоматическое отключение сервисов для избежание каскадного падения
4. Sage - разделение  большой транзакции на несколько маленьких, чтобы локально обрабатывать или откатывать.

# Логирование 
## Общая
Важно отслеживать состояние работы кода и после прохождения определенных этапов сохранять данные об успешной и не очень части кода. Вместо консоли используется отдельный файл, куда это сохраняется. Есть возможность настроить разные хранилища для разных ответов. 

Частое использование ElasticSeatch - БД для логирования. 
@Slf4j - аннотация для логирования их lombok. Дефолтная реализация в Logback.
* info - информация;
* debug - как именно происходит отработка;
* error - ошибки и исключения;
* warn - предупреждение.
# ДОПОЛНИТЕЛЬНО
1. Асинхронно - не дожидаться ответа - Kafka;
   Синхронно - ждем ответа - REST, JDBC;
2. Integer a = 200; Integer b = 200; sopl(a == b) - false, потому что больше 127;
3. Лямбда выражения работают только с final.
4. JWT - headr.body.подпись
5. gRPC и REST - два подхода к взаимодействию сервисов. Чаще всего используется REST для клиент - сервис, gRPC - сервис - сервис.
   **gRPC** - двунаправленный стриминг, локальные функции. Нужно сформировать отдельный файл .proto с инструкциями, добавить все в build.gradle, используем @GrpcService, добавляем конфигурацию
   **REST** - архитектурный стиль, JSON через Http
6. SOAP - формат обмена сообщениями, ограничение структуры на верхнем уровне. XML поверх SOAP через HTTP
   Envelope (конверт) + Header (настройка) + Body (информация) + Fault (дополнение, не обязательно.)