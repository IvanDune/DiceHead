Есть ли смысл ставить syncronyzed на метод с Аннотацией @Transactional?
Реализовать задачу о банкомате. Интерпретировать ее на многопоточку
## Caffein

## RPS и Высоконагруженные тесты
Request per Second - при повышении нагрузки мы отказываемся от использовании БД на критическом уровне, переходим на асинхронный формат. Добавляем Redis для хранения данных, INCR для изменения значений, добавляем очередь из запросов (Kafka).

Может быть выше задержка, но система выдерживает нагрузку
``` java
redisTemplate.opsForValue().increment(key) // Инкрементируем значение
```
## ExceptionHandler
``` java 
// Исключение
public class ResourceNotFoundException extends RuntimeException {

    public ResourceNotFoundException(String message) {
        super(message);
    }
}
```

``` java
// Обработка исключения
@ControllerAdvice
public class GlobalExceptionHandler {

    @ExceptionHandler(ResourceNotFoundException.class)
    public ResponseEntity<Object> handleResourceNotFound(ResourceNotFoundException ex) {
        Map<String, Object> body = new HashMap<>();
        body.put("timestamp", LocalDateTime.now());
        body.put("message", ex.getMessage());
        body.put("status", HttpStatus.NOT_FOUND.value());

        return new ResponseEntity<>(body, HttpStatus.NOT_FOUND);
    }

    // Можно добавить и другие обработчики, например:
    @ExceptionHandler(Exception.class)
    public ResponseEntity<Object> handleGeneral(Exception ex) {
        Map<String, Object> body = new HashMap<>();
        body.put("timestamp", LocalDateTime.now());
        body.put("message", "Internal error: " + ex.getMessage());
        body.put("status", HttpStatus.INTERNAL_SERVER_ERROR.value());

        return new ResponseEntity<>(body, HttpStatus.INTERNAL_SERVER_ERROR);
    }
}
```

``` java
//Вызов обработчика
@GetMapping("/api/video/{id}")
public ResponseEntity<Video> getVideo(@PathVariable String id) {
    Video video = videoService.findById(id)
        .orElseThrow(() -> new ResourceNotFoundException("Video not found with id: " + id));

    return ResponseEntity.ok(video);
}
```
## ConcurrentHashMap
Потокобезопасная реализация HashMap, высокая производительность нет ключей null, использует compareAndSwap и syncronyzed.

## AtomicInteger
`AtomicInteger` — это класс из пакета `java.util.concurrent.atomic`, предоставляющий потокобезопасные атомарные операции с переменными типа `int` без использования синхронизации (`synchronized`).

| Метод                                 | Описание                                                                                |
| ------------------------------------- | --------------------------------------------------------------------------------------- |
| get()                                 | Возвращает текущее значение                                                             |
| set(int newValue)                     | Устанавливает значение                                                                  |
| incrementAndGet()                     | Увеличивает на 1 и возвращает новое значение                                            |
| getAndIncrement()                     | Возвращает текущее значение, затем увеличивает на 1                                     |
| decrementAndGet()                     | Уменьшает на 1 и возвращает новое значение                                              |
| getAndAdd(int delta)                  | Возвращает текущее значение, затем прибавляет delta                                     |
| compareAndSet(int expect, int update) | Если текущее значение равно `expect`, заменяет его на `update` (CAS — compare-and-swap) |

# Kafka и Redis
## Часть 1: Docker Compose (Kafka + Redis)
Создай файл `docker-compose.yml`:
``` java
version: '3.8'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.0.1
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  redis:
    image: redis:7
    ports:
      - "6379:6379"
```
Запускаем 
``` java
docker-compose up -d
```

## Часть 2: Сервис-продьюсер (producer-service)
build.gradle
``` java
dependencies {
    implementation 'org.springframework.boot:spring-boot-starter-web'
    implementation 'org.springframework.kafka:spring-kafka'
    implementation 'org.springframework.boot:spring-boot-starter-data-redis'
    implementation 'org.apache.commons:commons-lang3'
}
```
application.yml
``` java
spring:
  kafka:
    bootstrap-servers: localhost:9092
  redis:
    host: localhost
    port: 6379
```
KafkaProducerConfig
``` java
@Configuration
public class KafkaProducerConfig {
    @Bean
    public ProducerFactory<String, String> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}
```
RedisConfig
``` java
@Configuration
public class RedisConfig {
    @Bean
    public RedisTemplate<String, String> redisTemplate(RedisConnectionFactory connectionFactory) {
        RedisTemplate<String, String> template = new RedisTemplate<>();
        template.setConnectionFactory(connectionFactory);
        return template;
    }
}
```
PRODUCER
``` java
@RestController
@RequestMapping("/api/produce")
public class ProducerController {
    private final KafkaTemplate<String, String> kafkaTemplate;
    private final RedisTemplate<String, String> redisTemplate;

    public ProducerController(KafkaTemplate<String, String> kafkaTemplate, RedisTemplate<String, String> redisTemplate) {
        this.kafkaTemplate = kafkaTemplate;
        this.redisTemplate = redisTemplate;
    }

    @PostMapping
    public ResponseEntity<String> sendMessage(@RequestBody String message) {
        kafkaTemplate.send("demo-topic", message);
        redisTemplate.opsForValue().set("lastMessage", message);
        return ResponseEntity.ok("Message sent and cached in Redis");
    }
}
```
## Часть 3: Сервис-консьюмер (consumer-service)
build.gradle
``` java
dependencies {
    implementation 'org.springframework.boot:spring-boot-starter'
    implementation 'org.springframework.kafka:spring-kafka'
    implementation 'org.springframework.boot:spring-boot-starter-data-redis'
}
```
application.yml
``` java
spring:
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      group-id: demo-group
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
  redis:
    host: localhost
    port: 6379
```
KafkaConsumerConfig
``` java
@Configuration
public class KafkaConsumerConfig {
    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "demo-group");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        return new DefaultKafkaConsumerFactory<>(props);
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, String> factory =
                new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        return factory;
    }
}
```
RedisConfig такой же как и в Producer

MessageConsumer
``` java
@Component
public class MessageConsumer {
    private final RedisTemplate<String, String> redisTemplate;

    public MessageConsumer(RedisTemplate<String, String> redisTemplate) {
        this.redisTemplate = redisTemplate;
    }

    @KafkaListener(topics = "demo-topic", groupId = "demo-group")
    public void listen(String message) {
        System.out.println("Received: " + message);
        redisTemplate.opsForList().leftPush("receivedMessages", message);
    }
}
```

# Интервью
1. Чем `HashMap` отличается от `ConcurrentHashMap`?  Когда и почему ты бы использовал каждый из них?

`HashMap` — не потокобезопасная реализация Map, предназначенная для однопоточного или внешне синхронизированного использования.

`ConcurrentHashMap` — потокобезопасная реализация, оптимизированная для многопоточного доступа без глобальной блокировки.

В отличие от `Collections.synchronizedMap`, `ConcurrentHashMap` использует **тонкую синхронизацию**: блокировки на уровне бакетов и неблокирующие операции (CAS), что позволяет нескольким потокам читать и писать одновременно.

Итераторы у `ConcurrentHashMap` являются **weakly consistent** — они не выбрасывают `ConcurrentModificationException`, но могут не отражать все изменения.

Также `ConcurrentHashMap` не поддерживает `null` ключи и значения, чтобы избежать неоднозначности в конкурентной среде.

Использую `HashMap` в однопоточном коде или при внешней синхронизации, а `ConcurrentHashMap` — когда требуется высокая производительность при конкурентном доступе.

В `Map` метод `get(key)` возвращает:
- `null`, если **ключа нет**
- `null`, если **значение = null**

В **однопоточном** `HashMap` это допустимо.
В **многопоточном** случае:
- один поток может делать `put(key, null)`
- другой одновременно делает `get(key)`
- невозможно понять:  
    ➝ ключ удалили?  
    ➝ значение ещё не записалось?  
    ➝ значение реально `null`?

Чтобы:
- не вводить **двусмысленность**
- не усложнять реализацию блокировками
разработчики просто **запретили `null`**.

2. Чем `volatile` отличается от `synchronized`?  Когда `volatile` недостаточно?
`volatile` гарантирует **видимость изменений** переменной между потоками и запрещает переупорядочивание инструкций, но **не обеспечивает атомарность**.

Он подходит для простых флагов состояния или одноразовой публикации данных.

`synchronized` обеспечивает как **атомарность**, так и **видимость**, за счёт захвата монитора и правил Java Memory Model.

`volatile` недостаточно, когда операция состоит из нескольких шагов, например `i++` или check-then-act сценариев — в таких случаях требуется `synchronized` или атомарные классы из `java.util.concurrent`.

3. Почему `AtomicInteger` может быть потокобезопасным без `synchronized`?
`AtomicInteger` обеспечивает потокобезопасность за счёт атомарных CAS-операций, которые выполняются на уровне процессора без использования блокировок.

Это lock-free механизм: если операция не удалась из-за конкурентного изменения, она просто повторяется.

В отличие от `synchronized`, это лучше масштабируется при высокой конкуренции, но подходит не для всех сценариев.

4. Чем `ArrayList` отличается от `LinkedList`?  В каких сценариях ты бы выбрал каждый из них?
`ArrayList` основан на динамическом массиве и обеспечивает быстрый доступ по индексу — `O(1)`, но при вставках и удалениях в середине требует сдвига элементов.

`LinkedList` — двусвязный список, где операции вставки и удаления выполняются за `O(1)` **только если есть ссылка на нужный узел**, однако поиск по индексу занимает `O(n)`.

На практике `ArrayList` чаще предпочтительнее из-за лучшей локальности памяти и меньших накладных расходов, а `LinkedList` имеет смысл использовать для очередей или при работе через итераторы.

Иногда ArrayList может быть быстрее LinkedListа при вставке в середину, потому что элементы там лежат одним блоком, связанным. Когда в Списке ссылки указываеют на разрозненные объекты в памяти. Это затрудняет работу GC

5. Опиши жизненный цикл объекта в JVM:  от создания до удаления сборщиком мусора.
Объекты в Java создаются в куче, как правило в **Eden Space** **New Generation** молодого поколения.
Пока на объект существуют достижимые ссылки от GC Roots, он считается живым.
В процессе Minor GC короткоживущие объекты удаляются, а пережившие несколько сборок перемещаются в Old Generation.
Когда на объект больше не остаётся достижимых ссылок, он может быть удалён сборщиком мусора при следующей сборке, однако момент удаления не детерминирован.

**GC Roots** — это начальные точки, от которых сборщик мусора определяет достижимость объектов.

К ним относятся локальные переменные активных методов, статические поля классов, активные потоки и JNI-ссылки.

Все объекты, достижимые от GC Roots, считаются живыми и не подлежат сборке.

**Memory leak в Java** — это ситуация, когда объекты **логически больше не используются**, но остаются **достижимыми** через ссылки, из-за чего сборщик мусора не может их удалить.

5. Проблема с `ThreadLocal` возникает не из-за недоступности GC, а из-за того, что значения сохраняются в `ThreadLocalMap` внутри потока.

В пуле потоков потоки живут долго, и если не вызвать `remove()`, значения остаются достижимыми и не могут быть собраны сборщиком мусора.
Проблема с `ThreadLocal` возникает не из-за недоступности GC, а из-за того, что значения сохраняются в `ThreadLocalMap` внутри потока.

Поток живёт → объект достижим → GC не удаляет

6. Что такое Dependency Injection и зачем он нужен?  Как Spring его реализует?
Dependency Injection — это принцип, при котором объект не создаёт свои зависимости самостоятельно, а получает их извне.

Это снижает связность между классами, упрощает тестирование и замену реализаций.

В Spring DI реализуется через IoC-контейнер, который управляет жизненным циклом бинов и внедряет зависимости на основе конфигурации — через аннотации, Java-конфигурацию или XML.

Внедрение может происходить через конструктор, сеттеры или напрямую в поля, при этом предпочтительным считается конструкторный DI.


7. Какие способы внедрения зависимостей ты знаешь в Spring?  Какой считается предпочтительным и почему?
В Spring существуют constructor, setter и field injection.

Предпочтительным считается constructor injection, так как он гарантирует корректное состояние объекта при создании, позволяет использовать final поля и упрощает тестирование. - зависимости создаются **до создания бина**, - ошибки видны **на старте контекста**

Setter injection применяют для опциональных зависимостей, а field injection считается менее предпочтительным из-за сложности тестирования и скрытых зависимостей.

8. Чем `@Component`, `@Service` и `@Repository` отличаются друг от друга в Spring?

`@Component`, `@Service` и `@Repository` — это стереотипные аннотации Spring, используемые для component scanning и регистрации бинов в IoC-контейнере.

С точки зрения контейнера они эквивалентны, но семантически отражают роль класса в архитектуре.

`@Component` — базовая аннотация общего назначения.

`@Service` используется для сервисного слоя и бизнес-логики.

`@Repository` применяется для слоя доступа к данным и дополнительно включает механизм трансляции исключений из JDBC/JPA в иерархию `DataAccessException`.

9. В чём разница между `JDK Dynamic Proxy` и `CGLIB` и когда какой используется?
Spring использует JDK Dynamic Proxy, если бин реализует интерфейс, и CGLIB — если интерфейса нет.  
JDK proxy работает через интерфейсы, а CGLIB создаёт подкласс и переопределяет методы.  
Из-за этого CGLIB не работает с `final` классами и методами.