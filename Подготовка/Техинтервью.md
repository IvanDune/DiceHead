Есть ли смысл ставить syncronyzed на метод с Аннотацией @Transactional?
Реализовать задачу о банкомате. Интерпретировать ее на многопоточку
## Caffein

## RPS и Высоконагруженные тесты
Request per Second - при повышении нагрузки мы отказываемся от использовании БД на критическом уровне, переходим на асинхронный формат. Добавляем Redis для хранения данных, INCR для изменения значений, добавляем очередь из запросов (Kafka).

Может быть выше задержка, но система выдерживает нагрузку
``` java
redisTemplate.opsForValue().increment(key) // Инкрементируем значение
```
## ExceptionHandler
``` java 
// Исключение
public class ResourceNotFoundException extends RuntimeException {

    public ResourceNotFoundException(String message) {
        super(message);
    }
}
```

``` java
// Обработка исключения
@ControllerAdvice
public class GlobalExceptionHandler {

    @ExceptionHandler(ResourceNotFoundException.class)
    public ResponseEntity<Object> handleResourceNotFound(ResourceNotFoundException ex) {
        Map<String, Object> body = new HashMap<>();
        body.put("timestamp", LocalDateTime.now());
        body.put("message", ex.getMessage());
        body.put("status", HttpStatus.NOT_FOUND.value());

        return new ResponseEntity<>(body, HttpStatus.NOT_FOUND);
    }

    // Можно добавить и другие обработчики, например:
    @ExceptionHandler(Exception.class)
    public ResponseEntity<Object> handleGeneral(Exception ex) {
        Map<String, Object> body = new HashMap<>();
        body.put("timestamp", LocalDateTime.now());
        body.put("message", "Internal error: " + ex.getMessage());
        body.put("status", HttpStatus.INTERNAL_SERVER_ERROR.value());

        return new ResponseEntity<>(body, HttpStatus.INTERNAL_SERVER_ERROR);
    }
}
```

``` java
//Вызов обработчика
@GetMapping("/api/video/{id}")
public ResponseEntity<Video> getVideo(@PathVariable String id) {
    Video video = videoService.findById(id)
        .orElseThrow(() -> new ResourceNotFoundException("Video not found with id: " + id));

    return ResponseEntity.ok(video);
}
```
## ConcurrentHashMap
Потокобезопасная реализация HashMap, высокая производительность нет ключей null, использует compareAndSwap и syncronyzed.

## AtomicInteger
`AtomicInteger` — это класс из пакета `java.util.concurrent.atomic`, предоставляющий потокобезопасные атомарные операции с переменными типа `int` без использования синхронизации (`synchronized`).

| Метод                                 | Описание                                                                                |
| ------------------------------------- | --------------------------------------------------------------------------------------- |
| get()                                 | Возвращает текущее значение                                                             |
| set(int newValue)                     | Устанавливает значение                                                                  |
| incrementAndGet()                     | Увеличивает на 1 и возвращает новое значение                                            |
| getAndIncrement()                     | Возвращает текущее значение, затем увеличивает на 1                                     |
| decrementAndGet()                     | Уменьшает на 1 и возвращает новое значение                                              |
| getAndAdd(int delta)                  | Возвращает текущее значение, затем прибавляет delta                                     |
| compareAndSet(int expect, int update) | Если текущее значение равно `expect`, заменяет его на `update` (CAS — compare-and-swap) |

# Kafka и Redis
## Часть 1: Docker Compose (Kafka + Redis)
Создай файл `docker-compose.yml`:
``` java
version: '3.8'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.0.1
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  redis:
    image: redis:7
    ports:
      - "6379:6379"
```
Запускаем 
``` java
docker-compose up -d
```

## Часть 2: Сервис-продьюсер (producer-service)
build.gradle
``` java
dependencies {
    implementation 'org.springframework.boot:spring-boot-starter-web'
    implementation 'org.springframework.kafka:spring-kafka'
    implementation 'org.springframework.boot:spring-boot-starter-data-redis'
    implementation 'org.apache.commons:commons-lang3'
}
```
application.yml
``` java
spring:
  kafka:
    bootstrap-servers: localhost:9092
  redis:
    host: localhost
    port: 6379
```
KafkaProducerConfig
``` java
@Configuration
public class KafkaProducerConfig {
    @Bean
    public ProducerFactory<String, String> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}
```
RedisConfig
``` java
@Configuration
public class RedisConfig {
    @Bean
    public RedisTemplate<String, String> redisTemplate(RedisConnectionFactory connectionFactory) {
        RedisTemplate<String, String> template = new RedisTemplate<>();
        template.setConnectionFactory(connectionFactory);
        return template;
    }
}
```
PRODUCER
``` java
@RestController
@RequestMapping("/api/produce")
public class ProducerController {
    private final KafkaTemplate<String, String> kafkaTemplate;
    private final RedisTemplate<String, String> redisTemplate;

    public ProducerController(KafkaTemplate<String, String> kafkaTemplate, RedisTemplate<String, String> redisTemplate) {
        this.kafkaTemplate = kafkaTemplate;
        this.redisTemplate = redisTemplate;
    }

    @PostMapping
    public ResponseEntity<String> sendMessage(@RequestBody String message) {
        kafkaTemplate.send("demo-topic", message);
        redisTemplate.opsForValue().set("lastMessage", message);
        return ResponseEntity.ok("Message sent and cached in Redis");
    }
}
```
## Часть 3: Сервис-консьюмер (consumer-service)
build.gradle
``` java
dependencies {
    implementation 'org.springframework.boot:spring-boot-starter'
    implementation 'org.springframework.kafka:spring-kafka'
    implementation 'org.springframework.boot:spring-boot-starter-data-redis'
}
```
application.yml
``` java
spring:
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      group-id: demo-group
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
  redis:
    host: localhost
    port: 6379
```
KafkaConsumerConfig
``` java
@Configuration
public class KafkaConsumerConfig {
    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "demo-group");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        return new DefaultKafkaConsumerFactory<>(props);
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, String> factory =
                new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        return factory;
    }
}
```
RedisConfig такой же как и в Producer

MessageConsumer
``` java
@Component
public class MessageConsumer {
    private final RedisTemplate<String, String> redisTemplate;

    public MessageConsumer(RedisTemplate<String, String> redisTemplate) {
        this.redisTemplate = redisTemplate;
    }

    @KafkaListener(topics = "demo-topic", groupId = "demo-group")
    public void listen(String message) {
        System.out.println("Received: " + message);
        redisTemplate.opsForList().leftPush("receivedMessages", message);
    }
}
```